{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение на 12 место\n",
    "Хрыльченко Кирилл, Ambitious\n",
    "\n",
    "В папке utils лежит несколько моих скриптов со всякими штуками, нужными для сабмита:\n",
    "1. nn.py --- содержит простенькую модель\n",
    "2. train.py --- cv валидатор\n",
    "3. evaluate.py --- функции для оптимизации\n",
    "4. train.py --- класс для обучения модели\n",
    "\n",
    "P.S: если усреднить больше сидов, то даст и 7-е :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from utils.evaluate import calculate_miou, get_iou, calculate_minmax_loss, get_df_miou\n",
    "from utils.train import Trainer\n",
    "from utils.data import load_data\n",
    "\n",
    "from utils.nn import LinearModel\n",
    "from utils.train import Validator, HoldoutValidator\n",
    "from utils.data import Inference, denormalize\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "coords = ['Xmin', 'Ymin', 'Xbias', 'Ybias']\n",
    "GT_coords = ['Xmin_true', 'Ymin_true', 'Xbias_true', 'Ybias_true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'train': './data/train.csv', # путь к трейн сету\n",
    "    'test': './data/test.csv', # путь к тест сету\n",
    "    'targets': './data/targets.csv' # пусть к таргетам\n",
    "}\n",
    "\n",
    "#train, test, targets, stats = load_data(paths, normalize=True, bias=True, delete_zero=True)\n",
    "train, test, targets = load_data(paths, normalize=False, bias=True, delete_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.cls = nn.Linear(n_features, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.cls(x))\n",
    "    \n",
    "    def initialize(self, features, regularize=False):\n",
    "        self.regularize = regularize\n",
    "        if self.regularize:\n",
    "            self.reg_positions = []\n",
    "        n = len(features)\n",
    "        weight = []\n",
    "        for idx, word in enumerate(['Xmin_min', 'Ymin_min', 'Xbias_opt', 'Ybias_opt']):\n",
    "            pos = features.index(word)\n",
    "            if self.regularize:\n",
    "                self.reg_positions.append(n * idx + pos)\n",
    "            weight.append([0] * pos + [1] + [0] * (n - pos - 1))\n",
    "        self.cls.weight.data = torch.tensor(weight).float()\n",
    "        self.cls.bias.data = torch.zeros(4).float()\n",
    "        \n",
    "    def L1_loss(self, coef=1.):\n",
    "        flattened_weights = self.cls.weight.flatten()\n",
    "        \n",
    "        term_1 = coef * (1. - flattened_weights[self.reg_positions]).abs().sum()\n",
    "        \n",
    "        term_2 = flattened_weights[:self.reg_positions[0]].abs().sum()\n",
    "        for i in range(len(self.reg_positions) - 1):\n",
    "            term_2 += flattened_weights[self.reg_positions[i] + 1 : self.reg_positions[i + 1]].abs().sum()\n",
    "        term_2 += flattened_weights[self.reg_positions[i + 1] + 1: ].abs().sum() \n",
    "        term_2 += self.cls.bias.flatten().abs().sum()\n",
    "        term_2 *= coef \n",
    "        return term_1 + term_2\n",
    "    \n",
    "    def L2_loss(self, coef=1.):\n",
    "        flattened_weights = self.cls.weight.flatten()\n",
    "        \n",
    "        term_1 = coef * (1. - flattened_weights[self.reg_positions]).pow(2).sum()\n",
    "        \n",
    "        term_2 = flattened_weights[:self.reg_positions[0]].pow(2).sum()\n",
    "        for i in range(len(self.reg_positions) - 1):\n",
    "            term_2 += flattened_weights[self.reg_positions[i] + 1 : self.reg_positions[i + 1]].pow(2).sum()\n",
    "        term_2 += flattened_weights[self.reg_positions[i + 1] + 1: ].pow(2).sum()\n",
    "        term_2 += self.cls.bias.flatten().pow(2).sum()\n",
    "        term_2 *= coef / 2.\n",
    "        return term_1 + term_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemDataset(Dataset):\n",
    "    def __init__(self, df, targets=None):\n",
    "        df = df.copy()\n",
    "        for coord in ['X', 'Y']:\n",
    "            df['{}max'.format(coord)] = df['{}min'.format(coord)] + df['{}bias'.format(coord)]\n",
    "            \n",
    "        df['square'] = np.sqrt(df['Xbias'] * df['Ybias'])\n",
    "        data = df.groupby('item').agg({\n",
    "            'Xmin': ['min'],\n",
    "            'Ymin': ['min'],\n",
    "            'Xmax': ['max'],\n",
    "            'Ymax': ['max'],\n",
    "            'square': ['mean']\n",
    "        })\n",
    "        \n",
    "        data.columns = ['{}_{}'.format(first, second) for first, second in data.columns]\n",
    "        for coord in ['X', 'Y']:\n",
    "            data['{}bias_opt'.format(coord)] = data['{}max_max'.format(coord)] - data['{}min_min'.format(coord)]\n",
    "        data.drop(['Xmax_max', 'Ymax_max'], axis=1, inplace=True)\n",
    "        \n",
    "        for col in ['Xbias_opt', 'Ybias_opt', 'Xmin_min']:\n",
    "            data['{}_sq]'.format(col)] = data[col] ** 2 / 1000.\n",
    "\n",
    "        self.features = list(data.columns)\n",
    "        self.items = list(data.index)\n",
    "        self.data = data.values.astype(np.float32)\n",
    "        self.len = self.data.shape[0]\n",
    "        self.n_features = self.data.shape[1]\n",
    "        \n",
    "        self.targets = None\n",
    "        if targets is not None:\n",
    "            self.targets = targets.set_index('item').loc[self.items].values.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.targets is not None:\n",
    "            return self.data[idx], self.targets[idx]\n",
    "        else:\n",
    "            return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(df, targets):\n",
    "    ds = ItemDataset(df, targets)\n",
    "    return DataLoader(ds, batch_size=256)\n",
    "\n",
    "def make_model(ds):\n",
    "    model = LinearModel(ds.n_features)\n",
    "    model.initialize(ds.features, regularize=True)\n",
    "    return model\n",
    "\n",
    "def make_criterion(model):\n",
    "    criterion = lambda preds, targets: calculate_miou(preds, targets) + model.L2_loss(0.001) + \\\n",
    "        0.000001 * torch.pow(preds - targets, 2).sum(dim=1).mean(dim=0) / torch.pow(targets, 2).sum(dim=1).mean(dim=0)\n",
    "    return criterion\n",
    "\n",
    "def make_val_criterion(model):\n",
    "    val_criterion = lambda preds, targets: calculate_miou(preds, targets)\n",
    "    return val_criterion\n",
    "\n",
    "train_params = {\n",
    "    'n_epochs': 1000,\n",
    "    'patience': 80,\n",
    "    'n_restarts': 1,\n",
    "    'gamma': 0.05,\n",
    "    'verbose': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1, loss: 0.5927, epoch:  272, time: 10.521s\n",
      "fold:  2, loss: 0.5968, epoch:  562, time: 14.811s\n",
      "fold:  3, loss: 0.5935, epoch:  351, time: 8.179s\n",
      "fold:  4, loss: 0.5867, epoch:  258, time: 6.828s\n",
      "fold:  5, loss: 0.6009, epoch:  357, time: 6.467s\n",
      "mean: 0.5941, std: 0.0047\n",
      "\n",
      "fold:  1, loss: 0.6027, epoch:  301, time: 6.470s\n",
      "fold:  2, loss: 0.5572, epoch:  522, time: 8.342s\n",
      "fold:  3, loss: 0.5940, epoch:  321, time: 6.465s\n",
      "fold:  4, loss: 0.6168, epoch:  514, time: 9.160s\n",
      "fold:  5, loss: 0.5960, epoch:  226, time: 4.321s\n",
      "mean: 0.5933, std: 0.0198\n",
      "\n",
      "fold:  1, loss: 0.5822, epoch:  316, time: 5.360s\n",
      "fold:  2, loss: 0.6009, epoch:  272, time: 5.468s\n",
      "fold:  3, loss: 0.5993, epoch:  349, time: 6.638s\n",
      "fold:  4, loss: 0.5891, epoch:  394, time: 7.127s\n",
      "fold:  5, loss: 0.5959, epoch:  519, time: 8.619s\n",
      "mean: 0.5935, std: 0.0070\n",
      "\n",
      "fold:  1, loss: 0.5842, epoch:  474, time: 7.931s\n",
      "fold:  2, loss: 0.6070, epoch:  223, time: 4.830s\n",
      "fold:  3, loss: 0.5934, epoch:  574, time: 9.500s\n",
      "fold:  4, loss: 0.5792, epoch:  202, time: 5.685s\n",
      "fold:  5, loss: 0.6071, epoch:  317, time: 13.089s\n",
      "mean: 0.5942, std: 0.0115\n",
      "\n",
      "fold:  1, loss: 0.5775, epoch:  419, time: 9.983s\n",
      "fold:  2, loss: 0.5811, epoch:   99, time: 4.754s\n",
      "fold:  3, loss: 0.6002, epoch:  288, time: 7.181s\n",
      "fold:  4, loss: 0.5967, epoch:  432, time: 9.189s\n",
      "fold:  5, loss: 0.6107, epoch:  419, time: 10.814s\n",
      "mean: 0.5932, std: 0.0123\n",
      "\n",
      "fold:  1, loss: 0.6089, epoch:  348, time: 10.660s\n",
      "fold:  2, loss: 0.5652, epoch:  645, time: 13.721s\n",
      "fold:  3, loss: 0.5925, epoch:  399, time: 11.147s\n",
      "fold:  4, loss: 0.5867, epoch:  497, time: 12.799s\n",
      "fold:  5, loss: 0.6166, epoch:  308, time: 7.666s\n",
      "mean: 0.5940, std: 0.0180\n",
      "\n",
      "fold:  1, loss: 0.5959, epoch:  800, time: 14.997s\n",
      "fold:  2, loss: 0.6121, epoch:  474, time: 10.100s\n",
      "fold:  3, loss: 0.5770, epoch:  274, time: 7.235s\n",
      "fold:  4, loss: 0.5889, epoch:  344, time: 7.837s\n",
      "fold:  5, loss: 0.5969, epoch:  175, time: 6.584s\n",
      "mean: 0.5942, std: 0.0114\n",
      "\n",
      "fold:  1, loss: 0.5915, epoch:  304, time: 7.541s\n",
      "fold:  2, loss: 0.5951, epoch:  238, time: 7.716s\n",
      "fold:  3, loss: 0.6109, epoch:  473, time: 10.901s\n",
      "fold:  4, loss: 0.5875, epoch:  818, time: 18.757s\n",
      "fold:  5, loss: 0.5844, epoch:  262, time: 8.313s\n",
      "mean: 0.5939, std: 0.0092\n",
      "\n",
      "fold:  1, loss: 0.5959, epoch:  595, time: 14.881s\n",
      "fold:  2, loss: 0.5899, epoch:  216, time: 7.022s\n",
      "fold:  3, loss: 0.6039, epoch:  235, time: 7.663s\n",
      "fold:  4, loss: 0.5913, epoch:  669, time: 14.496s\n",
      "fold:  5, loss: 0.5885, epoch:  430, time: 9.323s\n",
      "mean: 0.5939, std: 0.0056\n",
      "\n",
      "fold:  1, loss: 0.5882, epoch:  483, time: 10.966s\n",
      "fold:  2, loss: 0.6031, epoch:  326, time: 5.817s\n",
      "fold:  3, loss: 0.5899, epoch:  419, time: 10.768s\n",
      "fold:  4, loss: 0.6023, epoch:  488, time: 10.635s\n",
      "fold:  5, loss: 0.5847, epoch:  221, time: 7.447s\n",
      "mean: 0.5936, std: 0.0076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_models = []\n",
    "\n",
    "for seed in range(10):\n",
    "    val = Validator(train, targets, n_splits=5, seed=seed)\n",
    "\n",
    "    models, losses = val.train(\n",
    "        make_dataloader, make_model, make_criterion, make_val_criterion, train_params, verbose=True\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    all_models += models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5773556 public\n",
    "\n",
    "inf = Inference(lambda df: ItemDataset(df))\n",
    "test_preds = inf.predict(test, all_models)\n",
    "\n",
    "#denormalize(test_preds, stats).to_csv('test_preds.csv', index=False, header=False)\n",
    "np.round(test_preds).to_csv('test_preds_10.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemId</th>\n",
       "      <th>Xmin</th>\n",
       "      <th>Ymin</th>\n",
       "      <th>Xmax</th>\n",
       "      <th>Ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>107.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>1117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>27.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>20.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>35.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>1256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>38.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>757.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156</td>\n",
       "      <td>67.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>163</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>179</td>\n",
       "      <td>98.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>186</td>\n",
       "      <td>78.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>215</td>\n",
       "      <td>185.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>1072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>225</td>\n",
       "      <td>38.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>227</td>\n",
       "      <td>175.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>1361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>247</td>\n",
       "      <td>43.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>275</td>\n",
       "      <td>21.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>311</td>\n",
       "      <td>72.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>1105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>399</td>\n",
       "      <td>67.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>1088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>421</td>\n",
       "      <td>48.0</td>\n",
       "      <td>931.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>1066.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>432</td>\n",
       "      <td>49.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1031.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    itemId   Xmin   Ymin   Xmax    Ymax\n",
       "0       18  107.0  629.0  756.0  1117.0\n",
       "1       19   27.0  559.0  138.0   704.0\n",
       "2       33   20.0  378.0  412.0   653.0\n",
       "3       62   35.0  822.0  631.0  1256.0\n",
       "4      114   38.0  569.0  231.0   757.0\n",
       "5      146    0.0  213.0  783.0   855.0\n",
       "6      156   67.0  801.0  159.0   884.0\n",
       "7      163   19.0  316.0  216.0   462.0\n",
       "8      164    0.0  145.0  469.0   576.0\n",
       "9      179   98.0  488.0  336.0   714.0\n",
       "10     186   78.0  882.0  993.0  1551.0\n",
       "11     215  185.0  634.0  784.0  1072.0\n",
       "12     225   38.0  705.0  107.0   758.0\n",
       "13     227  175.0  837.0  846.0  1361.0\n",
       "14     247   43.0  623.0  184.0   742.0\n",
       "15     275   21.0  462.0  715.0   946.0\n",
       "16     311   72.0  593.0  633.0  1105.0\n",
       "17     399   67.0  746.0  412.0  1088.0\n",
       "18     421   48.0  931.0  245.0  1066.0\n",
       "19     432   49.0  840.0  299.0  1031.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_preds).head(n=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
